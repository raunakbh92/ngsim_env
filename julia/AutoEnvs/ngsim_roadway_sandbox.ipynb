{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspired from demo.ipynb in NGSIM.jl\n",
    "- Takeaways\n",
    "    - 101 has 5 segments\n",
    "    - Start from bottom of screen, 1 is bottom of screen, 2 is exit ramp,\n",
    "    3 is straight section, 4 is entry to road till entry ramp \n",
    "    join point, 5 is entry ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <script class='js-collapse-script'>\n",
       "        var curMatch =\n",
       "            window.location.href\n",
       "            .match(/(.*?)\\/notebooks\\/.*\\.ipynb/);\n",
       "\n",
       "        curMatch = curMatch ||\n",
       "            window.location.href\n",
       "            .match(/(.*?)\\/apps\\/.*\\.ipynb/);\n",
       "\n",
       "        if ( curMatch ) {\n",
       "            $('head').append('<base href=\"' + curMatch[1] + '/\">');\n",
       "        }\n",
       "    </script>\n"
      ],
      "text/plain": [
       "HTML{String}(\"    <script class='js-collapse-script'>\\n        var curMatch =\\n            window.location.href\\n            .match(/(.*?)\\\\/notebooks\\\\/.*\\\\.ipynb/);\\n\\n        curMatch = curMatch ||\\n            window.location.href\\n            .match(/(.*?)\\\\/apps\\\\/.*\\\\.ipynb/);\\n\\n        if ( curMatch ) {\\n            \\$('head').append('<base href=\\\"' + curMatch[1] + '/\\\">');\\n        }\\n    </script>\\n\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script class='js-collapse-script' src='/assetserver/5dc1e185f8b2175037a0bb4bac5baa1c8ca39ea5-assets/webio/dist/bundle.js'></script>"
      ],
      "text/plain": [
       "HTML{String}(\"<script class='js-collapse-script' src='/assetserver/5dc1e185f8b2175037a0bb4bac5baa1c8ca39ea5-assets/webio/dist/bundle.js'></script>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script class='js-collapse-script' src='/assetserver/5dc1e185f8b2175037a0bb4bac5baa1c8ca39ea5-assets/providers/ijulia_setup.js'></script>"
      ],
      "text/plain": [
       "HTML{String}(\"<script class='js-collapse-script' src='/assetserver/5dc1e185f8b2175037a0bb4bac5baa1c8ca39ea5-assets/providers/ijulia_setup.js'></script>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "  <script class='js-collapse-script'>\n",
       "    $('.js-collapse-script').parent('.output_subarea').css('padding', '0');\n",
       "  </script>\n"
      ],
      "text/plain": [
       "HTML{String}(\"  <script class='js-collapse-script'>\\n    \\$('.js-collapse-script').parent('.output_subarea').css('padding', '0');\\n  </script>\\n\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using NGSIM\n",
    "using AutomotiveDrivingModels\n",
    "using AutoViz\n",
    "using Interact # For slider bar trajectory propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "roadway = ROADWAY_101;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(scene) #108\n",
    "fieldnames(scene) #n, entitities\n",
    "typeof(scene.entities) # array of records\n",
    "size(scene.entities) #500\n",
    "typeof(scene.entities[1]) # Records.entity\n",
    "fieldnames(scene.entities[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video making using recorded cars on ngsim\n",
    "- Trajdatas is what the car trajectories are stored in\n",
    "- We want to color the ego vehicle differently to be able to see it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument 1 loads i101 7:50 to 8:05.\n",
    "# load_trajdata function defined in NGSIM.jl/src/trajdata.jl\n",
    "td1 = load_trajdata(1); \n",
    "\n",
    "scene = Scene(500)\n",
    "egoid = 546\n",
    "\n",
    "# Drive here in the notebook. Replay the trajectory as recorded in the ngsim data\n",
    "@manipulate for i in 1000:2000\n",
    "    temp_scene = get!(scene,td1,i)\n",
    "    \n",
    "    carcolors = Dict{Int,Colorant}()\n",
    "    for veh in temp_scene\n",
    "        #@show veh.id\n",
    "        # if veh id matches the egoid color it blue otherwise green\n",
    "        carcolors[veh.id] = \n",
    "        in(veh.id, egoid) ? colorant\"blue\" : colorant\"green\"\n",
    "    end\n",
    "    render(temp_scene, ROADWAY_101, \n",
    "        cam=CarFollowCamera{Int}(546,5.0),\n",
    "#         cam=StaticCamera(VecE2(1966400, 570900), 5.0),\n",
    "#         cam=FitToContentCamera(0.),\n",
    "        car_colors=carcolors)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't reinvent the wheel: Use existing environment\n",
    "- For `observe!` from `Tim2DDriver` to work, had to make the following changes\n",
    "    - Had to modify `AutomotiveDrivingModels.jl/src/2d/vehicles/scene_records.jl` to extend\n",
    "the default length of the capacity in the record container from 100 to 300\n",
    "    - Did the same capacity extension in `Records.jl/src/frames.jl`, `QueueRecords.jl` and \n",
    "`ListRecords.jl`\n",
    "- Note that querying Tim2DDriver yields a `latLonAccel` return type. Had to create an array\n",
    "to enable these values to work with `step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "using AutoEnvs\n",
    "\n",
    "n_veh = 1\n",
    "filepath = Pkg.dir(\"NGSIM\", \"data\", \"trajdata_i101_trajectories-0805am-0820am.txt\")\n",
    "params = Dict(\n",
    "        \"trajectory_filepaths\"=>[filepath],\n",
    "        \"H\"=>50,\n",
    "        \"primesteps\"=>50,\n",
    "        \"n_veh\"=>n_veh,\n",
    "        \"remove_ngsim_veh\"=>false\n",
    ")\n",
    "# env = MultiagentNGSIMEnvVideoMaker(params)\n",
    "env = MultiagentNGSIMEnv(params);\n",
    "reset(env);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 0.1\n",
    "model = Tim2DDriver(timestep,mlane = MOBIL(timestep));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a series of images in /tmp/episode1\n",
    "# You can open the first and then press right arrow\n",
    "\n",
    "# a = ones(n_veh, 2)\n",
    "# a[2] = 0.0\n",
    "\n",
    "for _ in 1:100\n",
    "    render(env)\n",
    "    observe!(model, env.scene, env.roadway, env.ego_vehs[1].id)\n",
    "    latlonacc = rand(model)\n",
    "    a = [latlonacc.a_lon latlonacc.a_lat]\n",
    "    x, r, terminal, _ = step(env, a)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Union{Records.Entity{AutomotiveDrivingModels.VehicleState,AutomotiveDrivingModels.VehicleDef,Int64}, Void},1}:\n",
       " Vehicle(697, VehicleState(VecSE2({1966761.174, 570570.356}, -0.717), Frenet(RoadIndex({751, 0.745057}, {1, 1}), 228.845, -1.515, -0.042), 17.041), VehicleDef(CAR, 4.724, 1.798))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.ego_vehs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at sisl/gail-driver/julia/envs/Auto2D.jl function reel_drive\n",
    "# for video making inspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to figure out what input to give to get a sensible a from Tim2D\n",
    "# Look at get_actions method within \n",
    "# AutomotiveDrivingModels/src/interface/simulation.jl to get inspiration\n",
    "timestep = 0.1\n",
    "model = Tim2DDriver(timestep,\n",
    "        mlane = MOBIL(timestep))\n",
    "# \n",
    "set_desired_speed!(model, 10.0)\n",
    "reset(env)\n",
    "get!(env.scene, env.trajdatas[env.traj_idx], env.t)\n",
    "# for (i,veh) in enumerate(env.scene)\n",
    "# #     env.scene, env.trajdatas[env.traj_idx], env.t\n",
    "#     @show i    \n",
    "#     @show veh\n",
    "#     observe!(model, env.scene, env.roadway, veh.id)\n",
    "        @show rand(model)\n",
    "# end\n",
    "\n",
    "# a = rand(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Tim driver\n",
    "- Using the stadium2D demo from AutomotiveDrivingModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roadway = gen_stadium_roadway(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = Scene()\n",
    "push!(scene,Vehicle(VehicleState(VecSE2(10.0,-DEFAULT_LANE_WIDTH,0.0), roadway, 29.0), VehicleDef(), 1))\n",
    "push!(scene,Vehicle(VehicleState(VecSE2(40.0,0.0,0.0), roadway, 22.0), VehicleDef(), 2))\n",
    "push!(scene,Vehicle(VehicleState(VecSE2(70.0,-DEFAULT_LANE_WIDTH,0.0), roadway, 27.0), VehicleDef(), 3))\n",
    "\n",
    "car_colors = get_pastel_car_colors(scene)\n",
    "cam = FitToContentCamera()\n",
    "render(scene, roadway, cam=cam, car_colors=car_colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene[1].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutomotiveDrivingModels.observe!(model, scene, roadway, scene[1].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rand(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 0.1\n",
    "\n",
    "model = Tim2DDriver(timestep,\n",
    "        mlane = MOBIL(timestep),\n",
    "    )\n",
    "set_desired_speed!(model, 10.0)\n",
    "\n",
    "for (i,veh) in enumerate(scene)\n",
    "#     env.scene, env.trajdatas[env.traj_idx], env.t\n",
    "        observe!(model, env.scene, env.roadway, veh.id)\n",
    "        @show rand(model)\n",
    "end\n",
    "\n",
    "# nticks = 100\n",
    "# rec = SceneRecord(nticks+1, timestep)\n",
    "# simulate!(rec, scene, roadway, model, nticks)\n",
    "# render(rec[0], roadway, cam=cam, car_colors=car_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
