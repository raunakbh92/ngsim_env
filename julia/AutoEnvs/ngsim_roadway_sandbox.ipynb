{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspired from demo.ipynb in NGSIM.jl\n",
    "- Takeaways\n",
    "    - 101 has 5 segments\n",
    "    - Start from bottom of screen, 1 is bottom of screen, 2 is exit ramp,\n",
    "    3 is straight section, 4 is entry to road till entry ramp \n",
    "    join point, 5 is entry ramp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For `observe!` from `Tim2DDriver` to work, had to make the following changes\n",
    "    - Had to modify `AutomotiveDrivingModels.jl/src/2d/vehicles/scene_records.jl` to extend\n",
    "the default length of the capacity in the record container from 100 to 300\n",
    "    - Did the same capacity extension in `Records.jl/src/frames.jl`, `QueueRecords.jl` and \n",
    "`ListRecords.jl`\n",
    "- Note that querying Tim2DDriver yields a `latLonAccel` return type. Had to create an array\n",
    "to enable these values to work with `step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <script class='js-collapse-script'>\n",
       "        var curMatch =\n",
       "            window.location.href\n",
       "            .match(/(.*?)\\/notebooks\\/.*\\.ipynb/);\n",
       "\n",
       "        curMatch = curMatch ||\n",
       "            window.location.href\n",
       "            .match(/(.*?)\\/apps\\/.*\\.ipynb/);\n",
       "\n",
       "        if ( curMatch ) {\n",
       "            $('head').append('<base href=\"' + curMatch[1] + '/\">');\n",
       "        }\n",
       "    </script>\n"
      ],
      "text/plain": [
       "HTML{String}(\"    <script class='js-collapse-script'>\\n        var curMatch =\\n            window.location.href\\n            .match(/(.*?)\\\\/notebooks\\\\/.*\\\\.ipynb/);\\n\\n        curMatch = curMatch ||\\n            window.location.href\\n            .match(/(.*?)\\\\/apps\\\\/.*\\\\.ipynb/);\\n\\n        if ( curMatch ) {\\n            \\$('head').append('<base href=\\\"' + curMatch[1] + '/\\\">');\\n        }\\n    </script>\\n\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script class='js-collapse-script' src='/assetserver/5dc1e185f8b2175037a0bb4bac5baa1c8ca39ea5-assets/webio/dist/bundle.js'></script>"
      ],
      "text/plain": [
       "HTML{String}(\"<script class='js-collapse-script' src='/assetserver/5dc1e185f8b2175037a0bb4bac5baa1c8ca39ea5-assets/webio/dist/bundle.js'></script>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script class='js-collapse-script' src='/assetserver/5dc1e185f8b2175037a0bb4bac5baa1c8ca39ea5-assets/providers/ijulia_setup.js'></script>"
      ],
      "text/plain": [
       "HTML{String}(\"<script class='js-collapse-script' src='/assetserver/5dc1e185f8b2175037a0bb4bac5baa1c8ca39ea5-assets/providers/ijulia_setup.js'></script>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "  <script class='js-collapse-script'>\n",
       "    $('.js-collapse-script').parent('.output_subarea').css('padding', '0');\n",
       "  </script>\n"
      ],
      "text/plain": [
       "HTML{String}(\"  <script class='js-collapse-script'>\\n    \\$('.js-collapse-script').parent('.output_subarea').css('padding', '0');\\n  </script>\\n\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using NGSIM\n",
    "using AutomotiveDrivingModels\n",
    "using AutoViz\n",
    "using Interact # For slider bar trajectory propagation\n",
    "using Reel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "roadway = ROADWAY_101;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "using AutoEnvs\n",
    "\n",
    "n_veh = 3\n",
    "filepath = Pkg.dir(\"NGSIM\", \"data\", \n",
    "    \"trajdata_i101_trajectories-0805am-0820am.txt\")\n",
    "params = Dict(\n",
    "        \"trajectory_filepaths\"=>[filepath],\n",
    "        \"H\"=>200,\n",
    "        \"primesteps\"=>50,\n",
    "        \"n_veh\"=>n_veh,\n",
    "        \"remove_ngsim_veh\"=>false\n",
    ")\n",
    "# env = MultiagentNGSIMEnvVideoMaker(params)\n",
    "env = MultiagentNGSIMEnv(params);\n",
    "timestep = 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tim2DDriver(timestep,mlane = MOBIL(timestep));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from `sisl/gail-driver/validation/validation.jl`\n",
    "# Reduced T to 0.1 to see more aggressive driving\n",
    "# Now wondering how to make the blue vehicle change lanes\n",
    "mlon = IntelligentDriverModel(σ=0.1,k_spd=1.0,T=0.1,s_min=2.0,\n",
    "    a_max=3.0,d_cmf=2.5)\n",
    "mlat = ProportionalLaneTracker(σ=0.1, kp=3.0, kd=2.0)\n",
    "mlane = MOBIL(timestep,politeness=0.01,advantage_threshold=0.01)\n",
    "\n",
    "model = Tim2DDriver(timestep, mlon=mlon, mlat=mlat, mlane=mlane);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.n_veh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a series of images in /tmp/episode1\n",
    "# You can open the first and then press right arrow\n",
    "\n",
    "# a = ones(n_veh, 2)\n",
    "# a[2] = 0.0\n",
    "reset(env,random_seed=9);\n",
    "t_init = env.t\n",
    "\n",
    "# @show env.n_veh\n",
    "for _ in 1:200\n",
    "    \n",
    "    render(env)\n",
    "    \n",
    "    #------------------------------------------------\n",
    "    a = zeros(env.n_veh,2)\n",
    "#     @show a\n",
    "    for (jj,veh) in enumerate(env.ego_vehs)\n",
    "        observe!(model,env.scene,env.roadway,veh.id)\n",
    "#         @show jj\n",
    "        latlonacc = rand(model)\n",
    "        \n",
    "#         @show a[jj][1]\n",
    "#         @show latlonacc.a_lat\n",
    "        a[jj,1] = latlonacc.a_lat\n",
    "#         @show \"3\"\n",
    "        a[jj,2] = latlonacc.a_lon\n",
    "    end\n",
    "    \n",
    "    \n",
    "#     observe!(model, env.scene, env.roadway, env.ego_vehs[1].id)\n",
    "#     latlonacc = rand(model)\n",
    "#     a = [latlonacc.a_lon latlonacc.a_lat] # This form for AccelTurnRate\n",
    "#     a = [latlonacc.a_lat latlonacc.a_lon]   # This form for LatLonAccel\n",
    "\n",
    "        \n",
    "    # Note: We have modified env to use LatLonAccel instead of AccelTurnRate\n",
    "    x, r, terminal, _ = step(env, a)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function makevid(t,dt)\n",
    "    for _ in t:300\n",
    "    render(env)\n",
    "    observe!(model, env.scene, env.roadway, env.ego_vehs[1].id)\n",
    "    latlonacc = rand(model)\n",
    "    a = [latlonacc.a_lon latlonacc.a_lat]\n",
    "    x, r, terminal, _ = step(env, a)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset(env,random_seed=4)\n",
    "film = roll(makevid, fps=10, duration=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"mygif.gif\",film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at sisl/gail-driver/julia/envs/Auto2D.jl function reel_drive\n",
    "# for video making inspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video making using recorded cars on ngsim\n",
    "- Trajdatas is what the car trajectories are stored in\n",
    "- We want to color the ego vehicle differently to be able to see it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument 1 loads i101 7:50 to 8:05.\n",
    "# load_trajdata function defined in NGSIM.jl/src/trajdata.jl\n",
    "td1 = load_trajdata(1); \n",
    "\n",
    "scene = Scene(500)\n",
    "egoid = 546\n",
    "\n",
    "# Drive here in the notebook. Replay the trajectory as recorded in the ngsim data\n",
    "@manipulate for i in 1000:2000\n",
    "    temp_scene = get!(scene,td1,i)\n",
    "    \n",
    "    carcolors = Dict{Int,Colorant}()\n",
    "    for veh in temp_scene\n",
    "        #@show veh.id\n",
    "        # if veh id matches the egoid color it blue otherwise green\n",
    "        carcolors[veh.id] = \n",
    "        in(veh.id, egoid) ? colorant\"blue\" : colorant\"green\"\n",
    "    end\n",
    "    render(temp_scene, ROADWAY_101, \n",
    "        cam=CarFollowCamera{Int}(546,5.0),\n",
    "#         cam=StaticCamera(VecE2(1966400, 570900), 5.0),\n",
    "#         cam=FitToContentCamera(0.),\n",
    "        car_colors=carcolors)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
