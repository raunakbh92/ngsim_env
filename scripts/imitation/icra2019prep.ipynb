{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Written on 7 September 2018 by Raunak\n",
    "- The input trajectories to this file need to have `laneNum` as one of the attributes of the dictionary containing the actual data in the traj_lab_dict data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import hgail.misc.utils\n",
    "\n",
    "import utils\n",
    "import visualize_utils\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def filename2label(fn):\n",
    "    s = fn.find('-') + 1\n",
    "    e = fn.find('.')\n",
    "    return fn[s:e]\n",
    "\n",
    "filenames = [i for i in utils.NGSIM_FILENAME_TO_ID.keys() if '101' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------Load Expert Data----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_filepath = '../../data/trajectories/ngsim.h5'\n",
    "\n",
    "# Use this one if you need lane information\n",
    "#expert_filepath = '../../data/trajectories/ngsim_addLaneID.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the 0750-0805 timeperiod because that is the default filename\n",
    "# in the utils.load_data\n",
    "\n",
    "# Run a cell later to get the feature names\n",
    "expert = dict()\n",
    "expert = utils.load_data(expert_filepath, min_length=250, \\\n",
    "                         normalize_data=False, clip_std_multiple=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detective work on the expert stuff loaded in using utils.load_data\n",
    "print(expert['0750am-0805am']['observations'].shape)\n",
    "expertvels = expert['0750am-0805am']['observations'][:,2]\n",
    "#print(expertvels.shape)\n",
    "#plt.hist(expertvels,normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expertTimegaps = expert['0750am-0805am']['observations'][:,observation_indexes['timegap']]\n",
    "#print(expertTimegaps.shape)\n",
    "#print(expertTimegaps.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, names = utils.load_x_feature_names(\n",
    "    expert_filepath, 'trajdata_i101_trajectories-0750am-0805am.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relative_offset' 'relative_heading' 'velocity' 'length' 'width'\n",
      " 'lane_curvature' 'markerdist_left' 'markerdist_right' 'accel' 'jerk'\n",
      " 'turn_rate_global' 'angular_rate_global' 'turn_rate_frenet'\n",
      " 'angular_rate_frenet' 'timegap' 'timegap_is_avail' 'time_to_collision'\n",
      " 'time_to_collision_is_avail' 'is_colliding' 'out_of_lane'\n",
      " 'negative_velocity' 'distance_road_edge_left' 'distance_road_edge_right'\n",
      " 'lidar_1' 'lidar_2' 'lidar_3' 'lidar_4' 'lidar_5' 'lidar_6' 'lidar_7'\n",
      " 'lidar_8' 'lidar_9' 'lidar_10' 'lidar_11' 'lidar_12' 'lidar_13' 'lidar_14'\n",
      " 'lidar_15' 'lidar_16' 'lidar_17' 'lidar_18' 'lidar_19' 'lidar_20'\n",
      " 'rangerate_lidar_1' 'rangerate_lidar_2' 'rangerate_lidar_3'\n",
      " 'rangerate_lidar_4' 'rangerate_lidar_5' 'rangerate_lidar_6'\n",
      " 'rangerate_lidar_7' 'rangerate_lidar_8' 'rangerate_lidar_9'\n",
      " 'rangerate_lidar_10' 'rangerate_lidar_11' 'rangerate_lidar_12'\n",
      " 'rangerate_lidar_13' 'rangerate_lidar_14' 'rangerate_lidar_15'\n",
      " 'rangerate_lidar_16' 'rangerate_lidar_17' 'rangerate_lidar_18'\n",
      " 'rangerate_lidar_19' 'rangerate_lidar_20' 'fore_fore_dist'\n",
      " 'fore_fore_relative_vel' 'fore_fore_accel']\n"
     ]
    }
   ],
   "source": [
    "observation_indexes = dict([(names[i], i) for i in range(len(names))])\n",
    "print(names)\n",
    "del(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detective work on the expert stuff loaded in through \n",
    "# load_x_feature_names\n",
    "#print(names)\n",
    "print(type(x))\n",
    "print(x.shape) # The shape obtained from utils.load_x_feature_names\n",
    "print(x[0][2200][0])\n",
    "print(names)\n",
    "print(observation_indexes['is_colliding'])\n",
    "print(observation_indexes['timegap'])\n",
    "print(x[0,100:500:25,14])\n",
    "plt.plot(x[1000,:,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress scientific painful notation in printing\n",
    "np.set_printoptions(suppress=True)\n",
    "#print(names)\n",
    "#print(x[2000,271,:])\n",
    "print(x[:,:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied over from emergent metrics code. The function to calculate emergent stuff\n",
    "def calc_offroad(traj):\n",
    "    return float(len(traj['observations'][:,observation_indexes['out_of_lane']][\n",
    "        np.where(np.isclose(traj['observations'][:,observation_indexes['out_of_lane']],1))\n",
    "    ]))/ float(len(traj['observations']))\n",
    "\n",
    "# in case we want to use a different threshold for whatever reason\n",
    "def calc_offroad_manual(traj, thresh = -1.0): \n",
    "    num_offroad = float(len(traj['observations'][:,0][\n",
    "        np.where(np.minimum(\n",
    "            traj['observations'][:,observation_indexes['distance_road_edge_left']], \\\n",
    "            traj['observations'][:,observation_indexes['distance_road_edge_right']]) <= thresh)\n",
    "        ]))\n",
    "    return num_offroad / float(len(traj['observations']))\n",
    "\n",
    "def calc_hard_brake(traj, thresh = -3.0):\n",
    "    #traj should be unnormalized\n",
    "    return float(len(traj['observations'][:,observation_indexes['accel']][np.where(\\\n",
    "                traj['observations'][:,observation_indexes['accel']] <= thresh)])) \\\n",
    "                / float(len(traj['actions']))\n",
    "\n",
    "def calc_collisions(traj, expert=True, H=200, nveh=100, verbose = True):\n",
    "    if expert:\n",
    "        if verbose:\n",
    "            print(\"shape = \",traj['observations'].shape)\n",
    "            print(\"shape of is_colliding column = \",\\\n",
    "                  traj['observations'][:,observation_indexes['is_colliding']].shape)\n",
    "            print(\"len(traj[obs]) = \",len(traj['observations']))\n",
    "        return float(len(traj['observations'][:,observation_indexes['is_colliding']][\n",
    "            np.where(np.isclose(traj['observations'][:,observation_indexes['is_colliding']],1))\n",
    "        ]))/ float(len(traj['observations']))\n",
    "    else:\n",
    "        a = np.reshape(\n",
    "            traj['observations'][:,observation_indexes['is_colliding']], (H, nveh))[:50,:]\n",
    "        return np.mean(np.any(np.isclose(a, 1.0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_collisions(expert['0750am-0805am'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's experiment with the 'expert' gotten using load_data as opposed to that \n",
    "# gotten from load_x_feature_names\n",
    "myTraj = expert['0750am-0805am']\n",
    "print(myTraj.keys())\n",
    "print(myTraj['observations'][:,observation_indexes['laneid']].shape)\n",
    "explaneids = myTraj['observations'][:,observation_indexes['laneid']]\n",
    "print(explaneids[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here begins lane change stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(observation_indexes['is_colliding'])\n",
    "print(observation_indexes['laneid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting lane change rate for the ngsim data\n",
    "laneChangeNgsimData = x[:,:,observation_indexes['laneid']]\n",
    "#print(laneChangeNgsimData[0,2000:2290])\n",
    "print(laneChangeNgsimData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the transpose here. Looks like rows store the agent number and columns store the time\n",
    "ngsimLaneChangeRate = calcLaneChangeRateFor1Simulation(\n",
    "np.transpose(laneChangeNgsimData),n_agents = laneChangeNgsimData.shape[0],\\\n",
    "    max_steps = laneChangeNgsimData.shape[1], verbose=False)\n",
    "print(ngsimLaneChangeRate)\n",
    "\n",
    "# Dividing by number of timesteps\n",
    "#print(ngsimLaneChangeRate/laneChangeNgsimData.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating for 200 timestep windows\n",
    "verbose = True\n",
    "demolanechangerate = [] # Averaged over all agents. For every 200 timestep period\n",
    "for i in range(0,2400,200):\n",
    "    if verbose:\n",
    "        print(i)\n",
    "    \n",
    "    # Pick a 200 timestep window\n",
    "    lanechangedatawindow = laneChangeNgsimData[:,i:i+200]\n",
    "    if verbose:\n",
    "        print(\"window shape = \",lanechangedatawindow.shape)\n",
    "    lanechangerateperagent = calcLaneChangeRateFor1Simulation(\n",
    "        np.transpose(lanechangedatawindow),\\\n",
    "        n_agents = lanechangedatawindow.shape[0],\\\n",
    "        max_steps = lanechangedatawindow.shape[1], verbose=False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(lanechangerateperagent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngsim collision calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute collisions per agent given simulation data\n",
    "# Assume timesteps are rows\n",
    "# agent numbers are columns\n",
    "# This assumption according to the way we get our simulation data using trained policy\n",
    "# The something can be anything that is reported in binary such as\n",
    "# is_colliding, is_offroad, is_hardbraking\n",
    "def calcIsSOMETHINGRatePerAgentForOneSim(dataArray,n_agents=100,max_steps=200,verbose=False):\n",
    "    something = np.count_nonzero(dataArray)\n",
    "    print(\"something = \",something)\n",
    "    return something/n_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting collisions in the same way as we did with lane change rate\n",
    "verbose = False\n",
    "ngsim_collisiondata = x[:,:,observation_indexes['is_colliding']]\n",
    "print(ngsim_collisiondata.shape)\n",
    "for i in range(0,2400,200):\n",
    "    if verbose:\n",
    "        print(i)\n",
    "    \n",
    "    # Pick a 200 timestep window\n",
    "    colldatawindow = ngsim_collisiondata[:,i:i+200]\n",
    "    if verbose:\n",
    "        print(\"window shape = \",lanechangedatawindow.shape)\n",
    "    ngsimcollrateperagent = calcIsSOMETHINGRatePerAgentForOneSim(\n",
    "        np.transpose(colldatawindow),\\\n",
    "        n_agents = colldatawindow.shape[0],\\\n",
    "        max_steps = colldatawindow.shape[1], verbose=False)\n",
    "    \n",
    "    print(ngsimcollrateperagent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2150*2286*66)\n",
    "print(np.count_nonzero(x[:,:1000,:]))\n",
    "print(np.count_nonzero(x[:,1000:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------Experimenting with histogram------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babytest = np.array([1,1,3,4,1,1,5,2,7])\n",
    "plt.hist(babytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----Here begins anaysis of our trained policies------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(x, mean, std):\n",
    "    return (x * std) + mean\n",
    "\n",
    "# This is where we unnormalize / reshape for the multiagent viz case\n",
    "# reshape basically flattens each attribute of the trajectory\n",
    "def reformat_trajectories(traj_lab_dict, length = 200, multi=True, reshape=True, \n",
    "                          unnormalize_data=True):\n",
    "    for i, model in enumerate(model_labels):\n",
    "        trajs = traj_lab_dict[model][0]\n",
    "        params = hgail.misc.utils.load_params(params_filepaths[i])\n",
    "        for timeperiod in trajs:\n",
    "            for traj in timeperiod:\n",
    "                if multi:\n",
    "                    n_veh = traj['observations'].shape[1]\n",
    "                else:\n",
    "                    n_veh = 1\n",
    "                if unnormalize_data:\n",
    "                    for j in range(n_veh):\n",
    "                        traj['observations'][:,j] = unnormalize(\n",
    "                            traj['observations'][:,j], \n",
    "                            params['normalzing']['obs_mean'],\n",
    "                            np.sqrt(params['normalzing']['obs_var'])\n",
    "                        )\n",
    "                if reshape:\n",
    "                    for attr in traj.keys():\n",
    "                        shape = traj[attr].shape\n",
    "                        if multi:\n",
    "                            if len(shape) > 0 and shape[0] == length and shape[1] == n_veh:\n",
    "                                traj[attr] = traj[attr].reshape(length*n_veh, -1)\n",
    "                            else:\n",
    "                                print(attr)\n",
    "                                print(traj[attr].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the policy to be analyzed\n",
    "\n",
    "model_labels = [\n",
    "    'rails_smoothed_off_brake_1000_2_fine',\n",
    "    'multiagent_curr_1_fine'\n",
    "    #'laneidtest_0_1_fine' # To see x tracked as a step info\n",
    "]\n",
    "\n",
    "n_itrs = dict([(i, 1000) for i in model_labels])\n",
    "for i in model_labels:\n",
    "    if 'fine' in i:\n",
    "        n_itrs[i] = 200\n",
    "\n",
    "# Load the policy to be analyzed\n",
    "traj_lab_dict = \\\n",
    "visualize_utils.get_trajs_dict(\n",
    "model_labels, files_to_use = \\\n",
    "[utils.NGSIM_FILENAME_TO_ID[i] - 1 for i in filenames])\n",
    "\n",
    "valdirs, params_filepaths = \\\n",
    "visualize_utils.get_val_dirs_and_params_paths_d(\n",
    "model_labels,n_itrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformat_trajectories(traj_lab_dict, reshape=True, unnormalize_data=True, length=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------timegap calculation-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating timegap\n",
    "timegapWithSim = np.zeros(100)\n",
    "for i in range(len(timegapWithSim)):\n",
    "    traj_timegaps = traj_lab_dict[model_labels[0]][0][0][i]['observations'][:,observation_indexes['timegap']]\n",
    "    meanTimegapForThisSim = traj_timegaps.mean()\n",
    "    timegapWithSim[i] = meanTimegapForThisSim\n",
    "print(timegapWithSim.mean())\n",
    "#print(traj_timegaps.shape)\n",
    "#print(traj_timegaps.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----failed collision calculation---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collision rate calclation did not work because we did not reformat the trajectory\n",
    "# Note that for the corl policies, the observation indexes have to all be reduced\n",
    "# by 1 when the ngsim data loaded in includes lane id\n",
    "print(traj_lab_dict[model_labels[0]][0][0][0]['observations'][:,:,observation_indexes['is_colliding']-1].shape)\n",
    "policy_collisionData = traj_lab_dict[model_labels[0]][0][0][0]['observations'][\n",
    "    :,:,observation_indexes['is_colliding']-1]\n",
    "policy_collisionRate = calcIsSOMETHINGRatePerAgentForOneSim(policy_collisionData)\n",
    "print(policy_collisionRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----plot distributions of things---------------\n",
    "Don't forget to specify the attribute of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rails_smoothed_off_brake_1000_2_fine\n",
      "multiagent_curr_1_fine\n",
      "(2000000,)\n",
      "(2000000,)\n"
     ]
    }
   ],
   "source": [
    "# Delete the variables if already defined\n",
    "try:\n",
    "    psgailvals\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del(psgailvals)\n",
    "try:\n",
    "    railvals\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del(railvals)\n",
    "try:\n",
    "    expertvals\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del(expertvals)\n",
    "\n",
    "attributeOfInterest = 'velocity'\n",
    "idxOfInterest = observation_indexes[attributeOfInterest]\n",
    "\n",
    "psgailvals = np.array([])\n",
    "railvals = np.array([])\n",
    "\n",
    "# Loops over the simulations (there are 100 of them) and appends the\n",
    "# velocity data into one long vector so that we have data from all the \n",
    "# simulations to plot the distribution over\n",
    "for label in model_labels:\n",
    "        print(label)\n",
    "        trajs = traj_lab_dict[label][0][0]\n",
    "        for sim in trajs:\n",
    "            if label == 'multiagent_curr_1_fine':\n",
    "                psgailvals = np.append(\n",
    "                    psgailvals,sim['observations'][:,idxOfInterest])\n",
    "            if label == 'rails_smoothed_off_brake_1000_2_fine':\n",
    "                railvals = np.append(\n",
    "                    railvals,sim['observations'][:,idxOfInterest])\n",
    "\n",
    "\n",
    "print(psgailvals.shape)\n",
    "print(railvals.shape)\n",
    "expertvals = expert['observations'][:,idxOfInterest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  [array([ 0.02197823,  0.01833123,  0.0271533 ,  0.04172117,  0.06111829,\n",
      "        0.09578822,  0.10513201,  0.06400401,  0.03895683,  0.02581671]), array([ 0.03628214,  0.03550657,  0.0458844 ,  0.05883205,  0.06655428,\n",
      "        0.06576505,  0.06042506,  0.05027638,  0.04377696,  0.03669711]), array([ 0.11177917,  0.11590024,  0.09807617,  0.08511598,  0.05335144,\n",
      "        0.02413454,  0.00846899,  0.0021894 ,  0.00069267,  0.0002914 ])]\n",
      "bins =  [  0.   2.   4.   6.   8.  10.  12.  14.  16.  18.  20.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa957455710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9332a7208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=1)\n",
    "\n",
    "# With the expert present\n",
    "colors = ['black','blue','orange']\n",
    "if attributeOfInterest == 'velocity':\n",
    "    binRange = (0,20)\n",
    "if attributeOfInterest == 'accel':\n",
    "    binRange = (-1,1)\n",
    "if attributeOfInterest == 'timegap':\n",
    "    binRange = (0,10)\n",
    "if attributeOfInterest == 'turn_rate_global':\n",
    "    binRange = (-0.25,0.25)\n",
    "n, bins, patches = axes.hist([expertvals,railvals,psgailvals], \\\n",
    "          range = binRange, normed = True, color = colors, \\\n",
    "          label = ['NGSIM','RAILS','PS-GAIL'])\n",
    "\n",
    "print(\"n = \",n)\n",
    "print(\"bins = \",bins)\n",
    "axes.legend(prop={'size': 10})\n",
    "# plt.savefig(attributeOfInterest+'Distb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a list of 3 Lists of Patches objects>\n"
     ]
    }
   ],
   "source": [
    "print(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes you have run the above cell and its above rigmarole already \n",
    "# so that psgail_obs and rail_obs is defined\n",
    "psgailaccels = psgail_obs[:,observation_indexes['accel']]\n",
    "railaccels = rail_obs[:,observation_indexes['accel']]\n",
    "expertaccels = expert['0750am-0805am']['observations'][:,observation_indexes['accel']]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1,ncols=1)\n",
    "\n",
    "colors = ['black','blue','red']\n",
    "axes.hist([expertaccels,railaccels,psgailaccels], normed = True, color = colors, \\\n",
    "          label = ['NGSIM','RAILS','PS-GAIL'])\n",
    "axes.legend(prop={'size': 10})\n",
    "plt.savefig('Combined_AccelDistb.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----legacy: understanding traj_lab_dict structure-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meriDict = traj_lab_dict[model_labels[0]][0][0][0]\n",
    "laneInfoArray = meriDict['laneNum']\n",
    "print(\"lane array shape = \",laneInfoArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be 3, corresponding to the 3 time windows\n",
    "# aka 750-805, 805-810 and 810-825\n",
    "print(len(traj_lab_dict[model_labels[0]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be 100, corresponding to the 100 sims that we run\n",
    "# within the 1st time window i.e 750-805\n",
    "print(len(traj_lab_dict[model_labels[0]][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's give this list a name as it is useful\n",
    "listOfSims4TimeWindow1 = traj_lab_dict[model_labels[0]][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic 1: All lane changes are counted in the incrementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing two timesteps all cars in one go\n",
    "def calcLaneChangeRateFor1Simulation(dataArray,\\\n",
    "                                     n_agents = 100, max_steps = 200,\\\n",
    "                                    verbose = False):\n",
    "    prevLaneNumsVector = np.zeros(n_agents)\n",
    "    numLaneChanges = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        currentLaneNumsVector = dataArray[step,:]\n",
    "        if verbose:\n",
    "            # This should be (n_agents,100)\n",
    "            print(currentLaneNumsVector.shape)\n",
    "            \n",
    "        laneChangesVector = currentLaneNumsVector - prevLaneNumsVector\n",
    "        numLaneChanges += np.count_nonzero(laneChangesVector)\n",
    "        \n",
    "        prevLaneNumsVector = currentLaneNumsVector\n",
    "    \n",
    "    # Plot the lanes at the end of the 20 second simulation\n",
    "    if verbose:\n",
    "        print(currentLaneNumsVector)\n",
    "        plt.plot(currentLaneNumsVector)\n",
    "    \n",
    "    return numLaneChanges/n_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation for 1 simulation\n",
    "testLaneChangeRate = calcLaneChangeRateFor1Simulation(\n",
    "listOfSims4TimeWindow1[76]['laneNum'], verbose=False)\n",
    "print(testLaneChangeRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lane change rate for every simulation and then average the result\n",
    "laneChangeRateArray = np.zeros(len(listOfSims4TimeWindow1))\n",
    "for i in range(len(listOfSims4TimeWindow1)):\n",
    "    laneChangeRateArray[i] = \\\n",
    "    calcLaneChangeRateFor1Simulation(listOfSims4TimeWindow1[i]['laneNum'])\n",
    "print(np.mean(laneChangeRateArray))\n",
    "\n",
    "# Dividing by the number of timesteps\n",
    "print(np.mean(laneChangeRateArray)/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic 2: At least one lane change means increment by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the per car logic over one whole simulation\n",
    "def calcCarWiseLaneChangeRateForOneSim(dataArray,\\\n",
    "                                     n_agents = 100, max_steps = 200,\\\n",
    "                                    verbose = False):\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Number of cars = \",dataArray.shape[1])\n",
    "    \n",
    "    # Assume all cars have not changed lane to start with\n",
    "    carHasChangedLane = np.zeros(dataArray.shape[1])\n",
    "    \n",
    "    \n",
    "    # Iterate over all the columns of the data array\n",
    "    # aka all the cars one by one\n",
    "    for i in range(dataArray.shape[1]):\n",
    "        # Compare all elements of that column i.e. lane id in all\n",
    "        # timesteps to the top column i.e lane id in 1st timestep\n",
    "        # If they are not all equal, then the car i has at least one\n",
    "        # lane change so increment lane change counter by 1\n",
    "        # i.e. this particular car has changed lane once in the\n",
    "        # 20 second time window under consideration\n",
    "        if not(\n",
    "            np.all(np.isclose(dataArray[:,i],dataArray[0,i]))):\n",
    "            \n",
    "            carHasChangedLane[i] = 1\n",
    "    \n",
    "    numCarsThatHaveChangedLanes = np.sum(carHasChangedLane)\n",
    "    return numCarsThatHaveChangedLanes/n_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLaneChangeRate = calcCarWiseLaneChangeRateForOneSim(\n",
    "listOfSims4TimeWindow1[17]['laneNum'],verbose=True)\n",
    "print(testLaneChangeRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the lane id to see whether that on-ramp or off-ramp is\n",
    "# causing problems\n",
    "def plotCarLaneIDOverTime(dataArray,carNum,verbose=True):\n",
    "    if verbose:\n",
    "        print(\"Selected car number is \",carNum)\n",
    "    plt.plot(dataArray[:,carNum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCarLaneIDOverTime(\n",
    "    listOfSims4TimeWindow1[17]['laneNum'],27,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------lane change calculation for every agent-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Philosophy for lane change and timegap calculation\n",
    "- Loop over all polices\n",
    "  - Loop over all 100 simulations\n",
    "    - Loop over all cars\n",
    "      - Loop over all timesteps.Find number of lane changes. Find average timegap over all timesteps.\n",
    "    - Average over the number of cars\n",
    " - Average over the number of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import hgail.misc.utils\n",
    "\n",
    "import utils\n",
    "import visualize_utils\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def filename2label(fn):\n",
    "    s = fn.find('-') + 1\n",
    "    e = fn.find('.')\n",
    "    return fn[s:e]\n",
    "\n",
    "filenames = [i for i in utils.NGSIM_FILENAME_TO_ID.keys() if '101' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load policies\n",
    "\n",
    "model_labels = [\n",
    "    'rails_smoothed_off_brake_1000_2_fine',\n",
    "    'multiagent_rails_2000_2_fine',\n",
    "    'multiagent_curr_1_fine'\n",
    "    #'laneidtest_0_1_fine' # To see x tracked as a step info\n",
    "]\n",
    "\n",
    "n_itrs = dict([(i, 1000) for i in model_labels])\n",
    "for i in model_labels:\n",
    "    if 'fine' in i:\n",
    "        n_itrs[i] = 200\n",
    "\n",
    "traj_lab_dict = \\\n",
    "visualize_utils.get_trajs_dict(\n",
    "model_labels, files_to_use = \\\n",
    "[utils.NGSIM_FILENAME_TO_ID[i] - 1 for i in filenames])\n",
    "\n",
    "valdirs, params_filepaths = \\\n",
    "visualize_utils.get_val_dirs_and_params_paths_d(\n",
    "model_labels,n_itrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a scalar: number of lane changes for every car averaged over all cars\n",
    "def numLaneChangesAveragedOverCars(dataArray,\\\n",
    "                                     n_agents = 100, max_steps = 200,\\\n",
    "                                    verbose = False):\n",
    "\n",
    "    laneChangesForEveryCar = np.zeros(n_agents)\n",
    "    \n",
    "    # Loop over all the agents\n",
    "    for agentNum in range(n_agents):\n",
    "        \n",
    "        # Initialize counter for number of lane changes\n",
    "        # Loop over all timesteps aka go through the entire trajectory\n",
    "        #     for the agent being considered\n",
    "        laneChangeData = dataArray[:,agentNum]\n",
    "        numLaneChanges = 0\n",
    "        \n",
    "        \n",
    "        for timestep in range(max_steps-1): # End 1 before as comparing succesive elems\n",
    "            if laneChangeData[timestep] != laneChangeData[timestep + 1]:\n",
    "                numLaneChanges = numLaneChanges + 1\n",
    "        \n",
    "        # Insert into the storage area\n",
    "        laneChangesForEveryCar[agentNum] = numLaneChanges\n",
    "    \n",
    "    # Return the average number of lane changes by averaging over number of cars\n",
    "    return np.mean(laneChangesForEveryCar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Calculate the average lane change rate over all simulations for all policies-----------\n",
    "\n",
    "# Loop over the different policies\n",
    "for label in model_labels:\n",
    "        print(label)\n",
    "        trajs = traj_lab_dict[label][0][0]\n",
    "        \n",
    "        # Loop over all the 100 simulations\n",
    "        laneChangesAvgPerCarForEverySim = np.zeros(len(trajs))\n",
    "        \n",
    "        for simNum, sim in enumerate(trajs):\n",
    "            laneChangesAvgPerCarForEverySim[simNum] = \\\n",
    "            numLaneChangesAveragedOverCars(sim['laneNum'])\n",
    "            \n",
    "        print(np.mean(laneChangesAvgPerCarForEverySim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------timegap begins here--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cautions:\n",
    "- Unlike the above lane change rate calculation, this one needs reformatted trajectories because it uses data from within `observations`\n",
    "- It also will be best to generate the `observation_indexes` using the `ngsim.h5` (and not the lane id added verion) to get the correct `timegap` index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import hgail.misc.utils\n",
    "\n",
    "import utils\n",
    "import visualize_utils\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def filename2label(fn):\n",
    "    s = fn.find('-') + 1\n",
    "    e = fn.find('.')\n",
    "    return fn[s:e]\n",
    "\n",
    "filenames = [i for i in utils.NGSIM_FILENAME_TO_ID.keys() if '101' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the observation index\n",
    "expert_filepath = '../../data/trajectories/ngsim.h5'\n",
    "x, names = utils.load_x_feature_names(\n",
    "    expert_filepath, 'trajdata_i101_trajectories-0750am-0805am.txt')\n",
    "observation_indexes = dict([(names[i], i) for i in range(len(names))])\n",
    "print(names)\n",
    "del(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load policies\n",
    "\n",
    "model_labels = [\n",
    "    'rails_smoothed_off_brake_1000_2_fine',\n",
    "    'multiagent_rails_2000_2_fine',\n",
    "    'multiagent_curr_1_fine'\n",
    "    #'laneidtest_0_1_fine' # To see x tracked as a step info\n",
    "]\n",
    "\n",
    "n_itrs = dict([(i, 1000) for i in model_labels])\n",
    "for i in model_labels:\n",
    "    if 'fine' in i:\n",
    "        n_itrs[i] = 200\n",
    "\n",
    "traj_lab_dict = \\\n",
    "visualize_utils.get_trajs_dict(\n",
    "model_labels, files_to_use = \\\n",
    "[utils.NGSIM_FILENAME_TO_ID[i] - 1 for i in filenames])\n",
    "\n",
    "valdirs, params_filepaths = \\\n",
    "visualize_utils.get_val_dirs_and_params_paths_d(\n",
    "model_labels,n_itrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(x, mean, std):\n",
    "    return (x * std) + mean\n",
    "\n",
    "# This is where we unnormalize / reshape for the multiagent viz case\n",
    "# reshape basically flattens each attribute of the trajectory\n",
    "def reformat_trajectories(traj_lab_dict, length = 200, multi=True, reshape=True, \n",
    "                          unnormalize_data=True):\n",
    "    for i, model in enumerate(model_labels):\n",
    "        trajs = traj_lab_dict[model][0]\n",
    "        params = hgail.misc.utils.load_params(params_filepaths[i])\n",
    "        for timeperiod in trajs:\n",
    "            for traj in timeperiod:\n",
    "                if multi:\n",
    "                    n_veh = traj['observations'].shape[1]\n",
    "                else:\n",
    "                    n_veh = 1\n",
    "                if unnormalize_data:\n",
    "                    for j in range(n_veh):\n",
    "                        traj['observations'][:,j] = unnormalize(\n",
    "                            traj['observations'][:,j], \n",
    "                            params['normalzing']['obs_mean'],\n",
    "                            np.sqrt(params['normalzing']['obs_var'])\n",
    "                        )\n",
    "                if reshape:\n",
    "                    for attr in traj.keys():\n",
    "                        shape = traj[attr].shape\n",
    "                        if multi:\n",
    "                            if len(shape) > 0 and shape[0] == length and shape[1] == n_veh:\n",
    "                                traj[attr] = traj[attr].reshape(length*n_veh, -1)\n",
    "                            else:\n",
    "                                print(attr)\n",
    "                                print(traj[attr].shape)\n",
    "\n",
    "### Note that reshape is set to false so we don't lost the agentwise information\n",
    "reformat_trajectories(traj_lab_dict, reshape=False, unnormalize_data=True, length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a scalar: avg timegap over horizon for every car averaged over all cars\n",
    "def timegapAvgOverHorizonAvgOverCars(dataArray,\\\n",
    "                                     n_agents = 100, max_steps = 200,\\\n",
    "                                    verbose = False):\n",
    "\n",
    "    avgTimegapForEveryCar = np.zeros(n_agents)\n",
    "    \n",
    "    # Loop over all the agents\n",
    "    for agentNum in range(n_agents):\n",
    "        \n",
    "        # Initialize counter for number of lane changes\n",
    "        # Loop over all timesteps aka go through the entire trajectory\n",
    "        #     for the agent being considered\n",
    "        timegapData = dataArray[:,agentNum]\n",
    "        timegapSum = 0.0\n",
    "        timegapSampleNum = 0.0\n",
    "        for timestep in range(max_steps):\n",
    "            if timegapData[timestep] != 30.0:\n",
    "                timegapSum = timegapSum + timegapData[timestep]\n",
    "                timegapSampleNum = timegapSampleNum + 1\n",
    "        \n",
    "        avgTimegapForEveryCar[agentNum] = timegapSum/timegapSampleNum\n",
    "        \n",
    "    # Return the average number of lane changes by averaging over number of cars\n",
    "    return np.mean(avgTimegapForEveryCar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Calculate the average timegap over all simulations for all policies-----------\n",
    "\n",
    "# Loop over the different policies\n",
    "for label in model_labels:\n",
    "        print(label)\n",
    "        trajs = traj_lab_dict[label][0][0]\n",
    "        \n",
    "        # Loop over all the 100 simulations\n",
    "        timegapForEverySim = np.zeros(len(trajs))\n",
    "        \n",
    "        # Every element i.e. sim is a (200,100,66) array\n",
    "        for simNum, sim in enumerate(trajs):\n",
    "            timegapForEverySim[simNum] = \\\n",
    "            timegapAvgOverHorizonAvgOverCars(\n",
    "                sim['observations'][:,:,observation_indexes['timegap']])\n",
    "            \n",
    "        print(np.mean(timegapForEverySim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------collision begins here--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cautions:\n",
    "- Unlike the above lane change rate calculation, this one needs reformatted trajectories because it uses data from within `observations`\n",
    "- It also will be best to generate the `observation_indexes` using the `ngsim.h5` (and not the lane id added verion) to get the correct `is_colliding` index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import hgail.misc.utils\n",
    "\n",
    "import utils\n",
    "import visualize_utils\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def filename2label(fn):\n",
    "    s = fn.find('-') + 1\n",
    "    e = fn.find('.')\n",
    "    return fn[s:e]\n",
    "\n",
    "filenames = [i for i in utils.NGSIM_FILENAME_TO_ID.keys() if '101' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the observation index\n",
    "expert_filepath = '../../data/trajectories/ngsim.h5'\n",
    "x, names = utils.load_x_feature_names(\n",
    "    expert_filepath, 'trajdata_i101_trajectories-0750am-0805am.txt')\n",
    "observation_indexes = dict([(names[i], i) for i in range(len(names))])\n",
    "#print(names)\n",
    "del(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load policies\n",
    "\n",
    "model_labels = [\n",
    "    'rails_smoothed_off_brake_1000_2_fine',\n",
    "    'multiagent_rails_2000_2_fine',\n",
    "    'multiagent_curr_1_fine'\n",
    "    #'laneidtest_0_1_fine' # To see x tracked as a step info\n",
    "]\n",
    "\n",
    "n_itrs = dict([(i, 1000) for i in model_labels])\n",
    "for i in model_labels:\n",
    "    if 'fine' in i:\n",
    "        n_itrs[i] = 200\n",
    "\n",
    "traj_lab_dict = \\\n",
    "visualize_utils.get_trajs_dict(\n",
    "model_labels, files_to_use = \\\n",
    "[utils.NGSIM_FILENAME_TO_ID[i] - 1 for i in filenames])\n",
    "\n",
    "valdirs, params_filepaths = \\\n",
    "visualize_utils.get_val_dirs_and_params_paths_d(\n",
    "model_labels,n_itrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(x, mean, std):\n",
    "    return (x * std) + mean\n",
    "\n",
    "# This is where we unnormalize / reshape for the multiagent viz case\n",
    "# reshape basically flattens each attribute of the trajectory\n",
    "def reformat_trajectories(traj_lab_dict, length = 200, multi=True, reshape=True, \n",
    "                          unnormalize_data=True):\n",
    "    for i, model in enumerate(model_labels):\n",
    "        trajs = traj_lab_dict[model][0]\n",
    "        params = hgail.misc.utils.load_params(params_filepaths[i])\n",
    "        for timeperiod in trajs:\n",
    "            for traj in timeperiod:\n",
    "                if multi:\n",
    "                    n_veh = traj['observations'].shape[1]\n",
    "                else:\n",
    "                    n_veh = 1\n",
    "                if unnormalize_data:\n",
    "                    for j in range(n_veh):\n",
    "                        traj['observations'][:,j] = unnormalize(\n",
    "                            traj['observations'][:,j], \n",
    "                            params['normalzing']['obs_mean'],\n",
    "                            np.sqrt(params['normalzing']['obs_var'])\n",
    "                        )\n",
    "                if reshape:\n",
    "                    for attr in traj.keys():\n",
    "                        shape = traj[attr].shape\n",
    "                        if multi:\n",
    "                            if len(shape) > 0 and shape[0] == length and shape[1] == n_veh:\n",
    "                                traj[attr] = traj[attr].reshape(length*n_veh, -1)\n",
    "                            else:\n",
    "                                print(attr)\n",
    "                                print(traj[attr].shape)\n",
    "\n",
    "### Note that reshape is set to false so we don't lost the agentwise information\n",
    "reformat_trajectories(traj_lab_dict, reshape=False, unnormalize_data=True, length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a scalar: has car collided once over its trajectory averaged over all cars\n",
    "def collisionAvgOverCars(dataArray,\\\n",
    "                                     n_agents = 100, max_steps = 200,\\\n",
    "                                    verbose = False):\n",
    "\n",
    "    collidedOnceForEveryCar = np.zeros(n_agents)\n",
    "    \n",
    "    # Loop over all the agents\n",
    "    for agentNum in range(n_agents):\n",
    "        \n",
    "        # Initialize counter for number of lane changes\n",
    "        # Loop over all timesteps aka go through the entire trajectory\n",
    "        #     for the agent being considered\n",
    "        collisionOverTrajectory = dataArray[:,agentNum]\n",
    "        hasCollidedAtLeastOnce = 0.0\n",
    "        \n",
    "        for timestep in range(max_steps):\n",
    "            if np.isclose(collisionOverTrajectory[timestep],1.0):\n",
    "                hasCollidedAtLeastOnce = 1.0\n",
    "                break\n",
    "        \n",
    "        collidedOnceForEveryCar[agentNum] = hasCollidedAtLeastOnce\n",
    "        \n",
    "        \n",
    "    # Average over number of cars\n",
    "#     print(\"collidedOnceForEveryCar = \",collidedOnceForEveryCar)\n",
    "#     print(collidedOnceForEveryCar.shape)\n",
    "    return np.min(collidedOnceForEveryCar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Calculate the average collisions over all simulations for all policies-----------\n",
    "\n",
    "# Loop over the different policies\n",
    "for label in model_labels:\n",
    "        print(label)\n",
    "        trajs = traj_lab_dict[label][0][0]\n",
    "        \n",
    "        # Loop over all the 100 simulations\n",
    "        collisionAvgForEverySim = np.zeros(len(trajs))\n",
    "        \n",
    "        # Every element i.e. sim is a (200,100,66) array\n",
    "        for simNum, sim in enumerate(trajs):\n",
    "            collisionAvgForEverySim[simNum] = \\\n",
    "            collisionAvgOverCars(\n",
    "                sim['observations'][:,:,observation_indexes['is_colliding']])\n",
    "            \n",
    "#         print(collisionAvgForEverySim)\n",
    "        print(np.mean(collisionAvgForEverySim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj_lab_dict['rails_smoothed_off_brake_1000_2_fine'][0][0][0]['observations'][:,:,observation_indexes['is_colliding']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
