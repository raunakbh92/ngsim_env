{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Written on 7 September 2018 by Raunak\n",
    "- The input trajectories to this file need to have `laneNum` as one of the attributes of the dictionary containing the actual data in the traj_lab_dict data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import hgail.misc.utils\n",
    "\n",
    "import utils\n",
    "import visualize_utils\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def filename2label(fn):\n",
    "    s = fn.find('-') + 1\n",
    "    e = fn.find('.')\n",
    "    return fn[s:e]\n",
    "\n",
    "filenames = [i for i in utils.NGSIM_FILENAME_TO_ID.keys() if '101' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------Load Expert Data----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_filepath = '../../data/trajectories/ngsim.h5'\n",
    "\n",
    "# Use this one if you need lane information\n",
    "#expert_filepath = '../../data/trajectories/ngsim_addLaneID.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the 0750-0805 timeperiod because that is the default filename\n",
    "# in the utils.load_data\n",
    "\n",
    "# Run a cell later to get the feature names\n",
    "expert = dict()\n",
    "expert = utils.load_data(expert_filepath, min_length=250, \\\n",
    "                         normalize_data=False, clip_std_multiple=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detective work on the expert stuff loaded in using utils.load_data\n",
    "print(expert['0750am-0805am']['observations'].shape)\n",
    "expertvels = expert['0750am-0805am']['observations'][:,2]\n",
    "#print(expertvels.shape)\n",
    "#plt.hist(expertvels,normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expertTimegaps = expert['0750am-0805am']['observations'][:,observation_indexes['timegap']]\n",
    "#print(expertTimegaps.shape)\n",
    "#print(expertTimegaps.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, names = utils.load_x_feature_names(\n",
    "    expert_filepath, 'trajdata_i101_trajectories-0750am-0805am.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_indexes = dict([(names[i], i) for i in range(len(names))])\n",
    "print(names)\n",
    "del(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detective work on the expert stuff loaded in through \n",
    "# load_x_feature_names\n",
    "#print(names)\n",
    "print(type(x))\n",
    "print(x.shape) # The shape obtained from utils.load_x_feature_names\n",
    "print(x[0][2200][0])\n",
    "print(names)\n",
    "print(observation_indexes['is_colliding'])\n",
    "print(observation_indexes['timegap'])\n",
    "print(x[0,100:500:25,14])\n",
    "plt.plot(x[1000,:,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress scientific painful notation in printing\n",
    "np.set_printoptions(suppress=True)\n",
    "#print(names)\n",
    "#print(x[2000,271,:])\n",
    "print(x[:,:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied over from emergent metrics code. The function to calculate emergent stuff\n",
    "def calc_offroad(traj):\n",
    "    return float(len(traj['observations'][:,observation_indexes['out_of_lane']][\n",
    "        np.where(np.isclose(traj['observations'][:,observation_indexes['out_of_lane']],1))\n",
    "    ]))/ float(len(traj['observations']))\n",
    "\n",
    "# in case we want to use a different threshold for whatever reason\n",
    "def calc_offroad_manual(traj, thresh = -1.0): \n",
    "    num_offroad = float(len(traj['observations'][:,0][\n",
    "        np.where(np.minimum(\n",
    "            traj['observations'][:,observation_indexes['distance_road_edge_left']], \\\n",
    "            traj['observations'][:,observation_indexes['distance_road_edge_right']]) <= thresh)\n",
    "        ]))\n",
    "    return num_offroad / float(len(traj['observations']))\n",
    "\n",
    "def calc_hard_brake(traj, thresh = -3.0):\n",
    "    #traj should be unnormalized\n",
    "    return float(len(traj['observations'][:,observation_indexes['accel']][np.where(\\\n",
    "                traj['observations'][:,observation_indexes['accel']] <= thresh)])) \\\n",
    "                / float(len(traj['actions']))\n",
    "\n",
    "def calc_collisions(traj, expert=True, H=200, nveh=100, verbose = True):\n",
    "    if expert:\n",
    "        if verbose:\n",
    "            print(\"shape = \",traj['observations'].shape)\n",
    "            print(\"shape of is_colliding column = \",\\\n",
    "                  traj['observations'][:,observation_indexes['is_colliding']].shape)\n",
    "            print(\"len(traj[obs]) = \",len(traj['observations']))\n",
    "        return float(len(traj['observations'][:,observation_indexes['is_colliding']][\n",
    "            np.where(np.isclose(traj['observations'][:,observation_indexes['is_colliding']],1))\n",
    "        ]))/ float(len(traj['observations']))\n",
    "    else:\n",
    "        a = np.reshape(\n",
    "            traj['observations'][:,observation_indexes['is_colliding']], (H, nveh))[:50,:]\n",
    "        return np.mean(np.any(np.isclose(a, 1.0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_collisions(expert['0750am-0805am'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's experiment with the 'expert' gotten using load_data as opposed to that \n",
    "# gotten from load_x_feature_names\n",
    "myTraj = expert['0750am-0805am']\n",
    "print(myTraj.keys())\n",
    "print(myTraj['observations'][:,observation_indexes['laneid']].shape)\n",
    "explaneids = myTraj['observations'][:,observation_indexes['laneid']]\n",
    "print(explaneids[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here begins lane change stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(observation_indexes['is_colliding'])\n",
    "print(observation_indexes['laneid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting lane change rate for the ngsim data\n",
    "laneChangeNgsimData = x[:,:,observation_indexes['laneid']]\n",
    "#print(laneChangeNgsimData[0,2000:2290])\n",
    "print(laneChangeNgsimData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the transpose here. Looks like rows store the agent number and columns store the time\n",
    "ngsimLaneChangeRate = calcLaneChangeRateFor1Simulation(\n",
    "np.transpose(laneChangeNgsimData),n_agents = laneChangeNgsimData.shape[0],\\\n",
    "    max_steps = laneChangeNgsimData.shape[1], verbose=False)\n",
    "print(ngsimLaneChangeRate)\n",
    "\n",
    "# Dividing by number of timesteps\n",
    "#print(ngsimLaneChangeRate/laneChangeNgsimData.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating for 200 timestep windows\n",
    "verbose = True\n",
    "demolanechangerate = [] # Averaged over all agents. For every 200 timestep period\n",
    "for i in range(0,2400,200):\n",
    "    if verbose:\n",
    "        print(i)\n",
    "    \n",
    "    # Pick a 200 timestep window\n",
    "    lanechangedatawindow = laneChangeNgsimData[:,i:i+200]\n",
    "    if verbose:\n",
    "        print(\"window shape = \",lanechangedatawindow.shape)\n",
    "    lanechangerateperagent = calcLaneChangeRateFor1Simulation(\n",
    "        np.transpose(lanechangedatawindow),\\\n",
    "        n_agents = lanechangedatawindow.shape[0],\\\n",
    "        max_steps = lanechangedatawindow.shape[1], verbose=False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(lanechangerateperagent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngsim collision calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute collisions per agent given simulation data\n",
    "# Assume timesteps are rows\n",
    "# agent numbers are columns\n",
    "# This assumption according to the way we get our simulation data using trained policy\n",
    "# The something can be anything that is reported in binary such as\n",
    "# is_colliding, is_offroad, is_hardbraking\n",
    "def calcIsSOMETHINGRatePerAgentForOneSim(dataArray,n_agents=100,max_steps=200,verbose=False):\n",
    "    something = np.count_nonzero(dataArray)\n",
    "    print(\"something = \",something)\n",
    "    return something/n_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting collisions in the same way as we did with lane change rate\n",
    "verbose = False\n",
    "ngsim_collisiondata = x[:,:,observation_indexes['is_colliding']]\n",
    "print(ngsim_collisiondata.shape)\n",
    "for i in range(0,2400,200):\n",
    "    if verbose:\n",
    "        print(i)\n",
    "    \n",
    "    # Pick a 200 timestep window\n",
    "    colldatawindow = ngsim_collisiondata[:,i:i+200]\n",
    "    if verbose:\n",
    "        print(\"window shape = \",lanechangedatawindow.shape)\n",
    "    ngsimcollrateperagent = calcIsSOMETHINGRatePerAgentForOneSim(\n",
    "        np.transpose(colldatawindow),\\\n",
    "        n_agents = colldatawindow.shape[0],\\\n",
    "        max_steps = colldatawindow.shape[1], verbose=False)\n",
    "    \n",
    "    print(ngsimcollrateperagent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2150*2286*66)\n",
    "print(np.count_nonzero(x[:,:1000,:]))\n",
    "print(np.count_nonzero(x[:,1000:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------Experimenting with histogram------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babytest = np.array([1,1,3,4,1,1,5,2,7])\n",
    "plt.hist(babytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----Here begins anaysis of our trained policies------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(x, mean, std):\n",
    "    return (x * std) + mean\n",
    "\n",
    "# This is where we unnormalize / reshape for the multiagent viz case\n",
    "# reshape basically flattens each attribute of the trajectory\n",
    "def reformat_trajectories(traj_lab_dict, length = 200, multi=True, reshape=True, \n",
    "                          unnormalize_data=True):\n",
    "    for i, model in enumerate(model_labels):\n",
    "        trajs = traj_lab_dict[model][0]\n",
    "        params = hgail.misc.utils.load_params(params_filepaths[i])\n",
    "        for timeperiod in trajs:\n",
    "            for traj in timeperiod:\n",
    "                if multi:\n",
    "                    n_veh = traj['observations'].shape[1]\n",
    "                else:\n",
    "                    n_veh = 1\n",
    "                if unnormalize_data:\n",
    "                    for j in range(n_veh):\n",
    "                        traj['observations'][:,j] = unnormalize(\n",
    "                            traj['observations'][:,j], \n",
    "                            params['normalzing']['obs_mean'],\n",
    "                            np.sqrt(params['normalzing']['obs_var'])\n",
    "                        )\n",
    "                if reshape:\n",
    "                    for attr in traj.keys():\n",
    "                        shape = traj[attr].shape\n",
    "                        if multi:\n",
    "                            if len(shape) > 0 and shape[0] == length and shape[1] == n_veh:\n",
    "                                traj[attr] = traj[attr].reshape(length*n_veh, -1)\n",
    "                            else:\n",
    "                                print(attr)\n",
    "                                print(traj[attr].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the policy to be analyzed\n",
    "\n",
    "model_labels = [\n",
    "    'rails_smoothed_off_brake_1000_2_fine',\n",
    "    'multiagent_curr_1_fine'\n",
    "    #'laneidtest_0_1_fine' # To see x tracked as a step info\n",
    "]\n",
    "\n",
    "n_itrs = dict([(i, 1000) for i in model_labels])\n",
    "for i in model_labels:\n",
    "    if 'fine' in i:\n",
    "        n_itrs[i] = 200\n",
    "\n",
    "# Load the policy to be analyzed\n",
    "traj_lab_dict = \\\n",
    "visualize_utils.get_trajs_dict(\n",
    "model_labels, files_to_use = \\\n",
    "[utils.NGSIM_FILENAME_TO_ID[i] - 1 for i in filenames])\n",
    "\n",
    "valdirs, params_filepaths = \\\n",
    "visualize_utils.get_val_dirs_and_params_paths_d(\n",
    "model_labels,n_itrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformat_trajectories(traj_lab_dict, reshape=True, unnormalize_data=True, length=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------timegap calculation-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating timegap\n",
    "timegapWithSim = np.zeros(100)\n",
    "for i in range(len(timegapWithSim)):\n",
    "    traj_timegaps = traj_lab_dict[model_labels[0]][0][0][i]['observations'][:,observation_indexes['timegap']]\n",
    "    meanTimegapForThisSim = traj_timegaps.mean()\n",
    "    timegapWithSim[i] = meanTimegapForThisSim\n",
    "print(timegapWithSim.mean())\n",
    "#print(traj_timegaps.shape)\n",
    "#print(traj_timegaps.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----failed collision calculation---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collision rate calclation did not work because we did not reformat the trajectory\n",
    "# Note that for the corl policies, the observation indexes have to all be reduced\n",
    "# by 1 when the ngsim data loaded in includes lane id\n",
    "print(traj_lab_dict[model_labels[0]][0][0][0]['observations'][:,:,observation_indexes['is_colliding']-1].shape)\n",
    "policy_collisionData = traj_lab_dict[model_labels[0]][0][0][0]['observations'][\n",
    "    :,:,observation_indexes['is_colliding']-1]\n",
    "policy_collisionRate = calcIsSOMETHINGRatePerAgentForOneSim(policy_collisionData)\n",
    "print(policy_collisionRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----plot distributions of things---------------\n",
    "Don't forget to specify the attribute of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the variables if already defined\n",
    "try:\n",
    "    psgailvals\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del(psgailvals)\n",
    "try:\n",
    "    railvals\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del(railvals)\n",
    "try:\n",
    "    expertvals\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del(expertvals)\n",
    "\n",
    "attributeOfInterest = 'accel'\n",
    "idxOfInterest = observation_indexes[attributeOfInterest]\n",
    "\n",
    "psgailvals = np.array([])\n",
    "railvals = np.array([])\n",
    "\n",
    "# Loops over the simulations (there are 100 of them) and appends the\n",
    "# velocity data into one long vector so that we have data from all the \n",
    "# simulations to plot the distribution over\n",
    "for label in model_labels:\n",
    "        print(label)\n",
    "        trajs = traj_lab_dict[label][0][0]\n",
    "        for sim in trajs:\n",
    "            if label == 'multiagent_curr_1_fine':\n",
    "                psgailvals = np.append(\n",
    "                    psgailvals,sim['observations'][:,idxOfInterest])\n",
    "            if label == 'rails_smoothed_off_brake_1000_2_fine':\n",
    "                railvals = np.append(\n",
    "                    railvals,sim['observations'][:,idxOfInterest])\n",
    "\n",
    "\n",
    "print(psgailvals.shape)\n",
    "print(railvals.shape)\n",
    "expertvals = expert['observations'][:,idxOfInterest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=1)\n",
    "\n",
    "# With the expert present\n",
    "colors = ['black','blue','orange']\n",
    "if attributeOfInterest == 'velocity':\n",
    "    binRange = (0,20)\n",
    "if attributeOfInterest == 'accel':\n",
    "    binRange = (-1,1)\n",
    "if attributeOfInterest == 'timegap':\n",
    "    binRange = (0,10)\n",
    "if attributeOfInterest == 'turn_rate_global':\n",
    "    binRange = (-0.25,0.25)\n",
    "axes.hist([expertvals,railvals,psgailvals], \\\n",
    "          range = binRange, normed = True, color = colors, \\\n",
    "          label = ['NGSIM','RAILS','PS-GAIL'])\n",
    "\n",
    "\n",
    "axes.legend(prop={'size': 10})\n",
    "plt.savefig(attributeOfInterest+'Distb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes you have run the above cell and its above rigmarole already \n",
    "# so that psgail_obs and rail_obs is defined\n",
    "psgailaccels = psgail_obs[:,observation_indexes['accel']]\n",
    "railaccels = rail_obs[:,observation_indexes['accel']]\n",
    "expertaccels = expert['0750am-0805am']['observations'][:,observation_indexes['accel']]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1,ncols=1)\n",
    "\n",
    "colors = ['black','blue','red']\n",
    "axes.hist([expertaccels,railaccels,psgailaccels], normed = True, color = colors, \\\n",
    "          label = ['NGSIM','RAILS','PS-GAIL'])\n",
    "axes.legend(prop={'size': 10})\n",
    "plt.savefig('Combined_AccelDistb.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----legacy: understanding traj_lab_dict structure-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meriDict = traj_lab_dict[model_labels[0]][0][0][0]\n",
    "laneInfoArray = meriDict['laneNum']\n",
    "print(\"lane array shape = \",laneInfoArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be 3, corresponding to the 3 time windows\n",
    "# aka 750-805, 805-810 and 810-825\n",
    "print(len(traj_lab_dict[model_labels[0]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be 100, corresponding to the 100 sims that we run\n",
    "# within the 1st time window i.e 750-805\n",
    "print(len(traj_lab_dict[model_labels[0]][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's give this list a name as it is useful\n",
    "listOfSims4TimeWindow1 = traj_lab_dict[model_labels[0]][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic 1: All lane changes are counted in the incrementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing two timesteps all cars in one go\n",
    "def calcLaneChangeRateFor1Simulation(dataArray,\\\n",
    "                                     n_agents = 100, max_steps = 200,\\\n",
    "                                    verbose = False):\n",
    "    prevLaneNumsVector = np.zeros(n_agents)\n",
    "    numLaneChanges = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        currentLaneNumsVector = dataArray[step,:]\n",
    "        if verbose:\n",
    "            # This should be (n_agents,100)\n",
    "            print(currentLaneNumsVector.shape)\n",
    "            \n",
    "        laneChangesVector = currentLaneNumsVector - prevLaneNumsVector\n",
    "        numLaneChanges += np.count_nonzero(laneChangesVector)\n",
    "        \n",
    "        prevLaneNumsVector = currentLaneNumsVector\n",
    "    \n",
    "    # Plot the lanes at the end of the 20 second simulation\n",
    "    if verbose:\n",
    "        print(currentLaneNumsVector)\n",
    "        plt.plot(currentLaneNumsVector)\n",
    "    \n",
    "    return numLaneChanges/n_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation for 1 simulation\n",
    "testLaneChangeRate = calcLaneChangeRateFor1Simulation(\n",
    "listOfSims4TimeWindow1[76]['laneNum'], verbose=False)\n",
    "print(testLaneChangeRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lane change rate for every simulation and then average the result\n",
    "laneChangeRateArray = np.zeros(len(listOfSims4TimeWindow1))\n",
    "for i in range(len(listOfSims4TimeWindow1)):\n",
    "    laneChangeRateArray[i] = \\\n",
    "    calcLaneChangeRateFor1Simulation(listOfSims4TimeWindow1[i]['laneNum'])\n",
    "print(np.mean(laneChangeRateArray))\n",
    "\n",
    "# Dividing by the number of timesteps\n",
    "print(np.mean(laneChangeRateArray)/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic 2: At least one lane change means increment by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the per car logic over one whole simulation\n",
    "def calcCarWiseLaneChangeRateForOneSim(dataArray,\\\n",
    "                                     n_agents = 100, max_steps = 200,\\\n",
    "                                    verbose = False):\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Number of cars = \",dataArray.shape[1])\n",
    "    \n",
    "    # Assume all cars have not changed lane to start with\n",
    "    carHasChangedLane = np.zeros(dataArray.shape[1])\n",
    "    \n",
    "    \n",
    "    # Iterate over all the columns of the data array\n",
    "    # aka all the cars one by one\n",
    "    for i in range(dataArray.shape[1]):\n",
    "        # Compare all elements of that column i.e. lane id in all\n",
    "        # timesteps to the top column i.e lane id in 1st timestep\n",
    "        # If they are not all equal, then the car i has at least one\n",
    "        # lane change so increment lane change counter by 1\n",
    "        # i.e. this particular car has changed lane once in the\n",
    "        # 20 second time window under consideration\n",
    "        if not(\n",
    "            np.all(np.isclose(dataArray[:,i],dataArray[0,i]))):\n",
    "            \n",
    "            carHasChangedLane[i] = 1\n",
    "    \n",
    "    numCarsThatHaveChangedLanes = np.sum(carHasChangedLane)\n",
    "    return numCarsThatHaveChangedLanes/n_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLaneChangeRate = calcCarWiseLaneChangeRateForOneSim(\n",
    "listOfSims4TimeWindow1[17]['laneNum'],verbose=True)\n",
    "print(testLaneChangeRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the lane id to see whether that on-ramp or off-ramp is\n",
    "# causing problems\n",
    "def plotCarLaneIDOverTime(dataArray,carNum,verbose=True):\n",
    "    if verbose:\n",
    "        print(\"Selected car number is \",carNum)\n",
    "    plt.plot(dataArray[:,carNum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCarLaneIDOverTime(\n",
    "    listOfSims4TimeWindow1[17]['laneNum'],27,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------lane change calculation for every agent-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Philosophy for lane change and timegap calculation\n",
    "- Loop over all polices\n",
    "  - Loop over all 100 simulations\n",
    "    - Loop over all cars\n",
    "      - Loop over all timesteps.Find number of lane changes. Find average timegap over all timesteps.\n",
    "    - Average over the number of cars\n",
    " - Average over the number of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import hgail.misc.utils\n",
    "\n",
    "import utils\n",
    "import visualize_utils\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def filename2label(fn):\n",
    "    s = fn.find('-') + 1\n",
    "    e = fn.find('.')\n",
    "    return fn[s:e]\n",
    "\n",
    "filenames = [i for i in utils.NGSIM_FILENAME_TO_ID.keys() if '101' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load policies\n",
    "\n",
    "model_labels = [\n",
    "    'rails_smoothed_off_brake_1000_2_fine',\n",
    "    'multiagent_rails_2000_2_fine',\n",
    "    'multiagent_curr_1_fine'\n",
    "    #'laneidtest_0_1_fine' # To see x tracked as a step info\n",
    "]\n",
    "\n",
    "n_itrs = dict([(i, 1000) for i in model_labels])\n",
    "for i in model_labels:\n",
    "    if 'fine' in i:\n",
    "        n_itrs[i] = 200\n",
    "\n",
    "traj_lab_dict = \\\n",
    "visualize_utils.get_trajs_dict(\n",
    "model_labels, files_to_use = \\\n",
    "[utils.NGSIM_FILENAME_TO_ID[i] - 1 for i in filenames])\n",
    "\n",
    "valdirs, params_filepaths = \\\n",
    "visualize_utils.get_val_dirs_and_params_paths_d(\n",
    "model_labels,n_itrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a scalar: number of lane changes for every car averaged over all cars\n",
    "def numLaneChangesAveragedOverCars(dataArray,\\\n",
    "                                     n_agents = 100, max_steps = 200,\\\n",
    "                                    verbose = False):\n",
    "\n",
    "    laneChangesForEveryCar = np.zeros(n_agents)\n",
    "    \n",
    "    # Loop over all the agents\n",
    "    for agentNum in range(n_agents):\n",
    "        \n",
    "        # Initialize counter for number of lane changes\n",
    "        # Loop over all timesteps aka go through the entire trajectory\n",
    "        #     for the agent being considered\n",
    "        laneChangeData = dataArray[:,agentNum]\n",
    "        numLaneChanges = 0\n",
    "        \n",
    "        \n",
    "        for timestep in range(max_steps-1): # End 1 before as comparing succesive elems\n",
    "            if laneChangeData[timestep] != laneChangeData[timestep + 1]:\n",
    "                numLaneChanges = numLaneChanges + 1\n",
    "        \n",
    "        # Insert into the storage area\n",
    "        laneChangesForEveryCar[agentNum] = numLaneChanges\n",
    "    \n",
    "    # Return the average number of lane changes by averaging over number of cars\n",
    "    return np.mean(laneChangesForEveryCar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rails_smoothed_off_brake_1000_2_fine\n",
      "1.3023\n",
      "multiagent_rails_2000_2_fine\n",
      "0.6512\n",
      "multiagent_curr_1_fine\n",
      "0.9156\n"
     ]
    }
   ],
   "source": [
    "#----Calculate the average lane change rate over all simulations for all policies-----------\n",
    "\n",
    "# Loop over the different policies\n",
    "for label in model_labels:\n",
    "        print(label)\n",
    "        trajs = traj_lab_dict[label][0][0]\n",
    "        \n",
    "        # Loop over all the 100 simulations\n",
    "        laneChangesAvgPerCarForEverySim = np.zeros(len(trajs))\n",
    "        \n",
    "        for simNum, sim in enumerate(trajs):\n",
    "            laneChangesAvgPerCarForEverySim[simNum] = \\\n",
    "            numLaneChangesAveragedOverCars(sim['laneNum'])\n",
    "            \n",
    "        print(np.mean(laneChangesAvgPerCarForEverySim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------timegap begins here--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cautions:\n",
    "- Unlike the above lane change rate calculation, this one needs reformatted trajectories because it uses data from within `observations`\n",
    "- It also will be best to generate the `observation_indexes` using the `ngsim.h5` (and not the lane id added verion) to get the correct `timegap` index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import hgail.misc.utils\n",
    "\n",
    "import utils\n",
    "import visualize_utils\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def filename2label(fn):\n",
    "    s = fn.find('-') + 1\n",
    "    e = fn.find('.')\n",
    "    return fn[s:e]\n",
    "\n",
    "filenames = [i for i in utils.NGSIM_FILENAME_TO_ID.keys() if '101' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relative_offset' 'relative_heading' 'velocity' 'length' 'width'\n",
      " 'lane_curvature' 'markerdist_left' 'markerdist_right' 'accel' 'jerk'\n",
      " 'turn_rate_global' 'angular_rate_global' 'turn_rate_frenet'\n",
      " 'angular_rate_frenet' 'timegap' 'timegap_is_avail' 'time_to_collision'\n",
      " 'time_to_collision_is_avail' 'is_colliding' 'out_of_lane'\n",
      " 'negative_velocity' 'distance_road_edge_left' 'distance_road_edge_right'\n",
      " 'lidar_1' 'lidar_2' 'lidar_3' 'lidar_4' 'lidar_5' 'lidar_6' 'lidar_7'\n",
      " 'lidar_8' 'lidar_9' 'lidar_10' 'lidar_11' 'lidar_12' 'lidar_13' 'lidar_14'\n",
      " 'lidar_15' 'lidar_16' 'lidar_17' 'lidar_18' 'lidar_19' 'lidar_20'\n",
      " 'rangerate_lidar_1' 'rangerate_lidar_2' 'rangerate_lidar_3'\n",
      " 'rangerate_lidar_4' 'rangerate_lidar_5' 'rangerate_lidar_6'\n",
      " 'rangerate_lidar_7' 'rangerate_lidar_8' 'rangerate_lidar_9'\n",
      " 'rangerate_lidar_10' 'rangerate_lidar_11' 'rangerate_lidar_12'\n",
      " 'rangerate_lidar_13' 'rangerate_lidar_14' 'rangerate_lidar_15'\n",
      " 'rangerate_lidar_16' 'rangerate_lidar_17' 'rangerate_lidar_18'\n",
      " 'rangerate_lidar_19' 'rangerate_lidar_20' 'fore_fore_dist'\n",
      " 'fore_fore_relative_vel' 'fore_fore_accel']\n"
     ]
    }
   ],
   "source": [
    "# Create the observation index\n",
    "expert_filepath = '../../data/trajectories/ngsim.h5'\n",
    "x, names = utils.load_x_feature_names(\n",
    "    expert_filepath, 'trajdata_i101_trajectories-0750am-0805am.txt')\n",
    "observation_indexes = dict([(names[i], i) for i in range(len(names))])\n",
    "print(names)\n",
    "del(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load policies\n",
    "\n",
    "model_labels = [\n",
    "    'rails_smoothed_off_brake_1000_2_fine',\n",
    "    'multiagent_rails_2000_2_fine',\n",
    "    'multiagent_curr_1_fine'\n",
    "    #'laneidtest_0_1_fine' # To see x tracked as a step info\n",
    "]\n",
    "\n",
    "n_itrs = dict([(i, 1000) for i in model_labels])\n",
    "for i in model_labels:\n",
    "    if 'fine' in i:\n",
    "        n_itrs[i] = 200\n",
    "\n",
    "traj_lab_dict = \\\n",
    "visualize_utils.get_trajs_dict(\n",
    "model_labels, files_to_use = \\\n",
    "[utils.NGSIM_FILENAME_TO_ID[i] - 1 for i in filenames])\n",
    "\n",
    "valdirs, params_filepaths = \\\n",
    "visualize_utils.get_val_dirs_and_params_paths_d(\n",
    "model_labels,n_itrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(x, mean, std):\n",
    "    return (x * std) + mean\n",
    "\n",
    "# This is where we unnormalize / reshape for the multiagent viz case\n",
    "# reshape basically flattens each attribute of the trajectory\n",
    "def reformat_trajectories(traj_lab_dict, length = 200, multi=True, reshape=True, \n",
    "                          unnormalize_data=True):\n",
    "    for i, model in enumerate(model_labels):\n",
    "        trajs = traj_lab_dict[model][0]\n",
    "        params = hgail.misc.utils.load_params(params_filepaths[i])\n",
    "        for timeperiod in trajs:\n",
    "            for traj in timeperiod:\n",
    "                if multi:\n",
    "                    n_veh = traj['observations'].shape[1]\n",
    "                else:\n",
    "                    n_veh = 1\n",
    "                if unnormalize_data:\n",
    "                    for j in range(n_veh):\n",
    "                        traj['observations'][:,j] = unnormalize(\n",
    "                            traj['observations'][:,j], \n",
    "                            params['normalzing']['obs_mean'],\n",
    "                            np.sqrt(params['normalzing']['obs_var'])\n",
    "                        )\n",
    "                if reshape:\n",
    "                    for attr in traj.keys():\n",
    "                        shape = traj[attr].shape\n",
    "                        if multi:\n",
    "                            if len(shape) > 0 and shape[0] == length and shape[1] == n_veh:\n",
    "                                traj[attr] = traj[attr].reshape(length*n_veh, -1)\n",
    "                            else:\n",
    "                                print(attr)\n",
    "                                print(traj[attr].shape)\n",
    "\n",
    "### Note that reshape is set to false so we don't lost the agentwise information\n",
    "reformat_trajectories(traj_lab_dict, reshape=False, unnormalize_data=True, length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a scalar: avg timegap over horizon for every car averaged over all cars\n",
    "def timegapAvgOverHorizonAvgOverCars(dataArray,\\\n",
    "                                     n_agents = 100, max_steps = 200,\\\n",
    "                                    verbose = False):\n",
    "\n",
    "    avgTimegapForEveryCar = np.zeros(n_agents)\n",
    "    \n",
    "    # Loop over all the agents\n",
    "    for agentNum in range(n_agents):\n",
    "        \n",
    "        # Initialize counter for number of lane changes\n",
    "        # Loop over all timesteps aka go through the entire trajectory\n",
    "        #     for the agent being considered\n",
    "        timegapData = dataArray[:,agentNum]\n",
    "        timegapSum = 0.0\n",
    "        timegapSampleNum = 0.0\n",
    "        for timestep in range(max_steps):\n",
    "            if timegapData[timestep] != 30.0:\n",
    "                timegapSum = timegapSum + timegapData[timestep]\n",
    "                timegapSampleNum = timegapSampleNum + 1\n",
    "        \n",
    "        avgTimegapForEveryCar[agentNum] = timegapSum/timegapSampleNum\n",
    "        \n",
    "    # Return the average number of lane changes by averaging over number of cars\n",
    "    return np.mean(avgTimegapForEveryCar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rails_smoothed_off_brake_1000_2_fine\n",
      "2.48254835214\n",
      "multiagent_rails_2000_2_fine\n",
      "2.15528916407\n",
      "multiagent_curr_1_fine\n",
      "4.06733140269\n"
     ]
    }
   ],
   "source": [
    "#----Calculate the average timegap over all simulations for all policies-----------\n",
    "\n",
    "# Loop over the different policies\n",
    "for label in model_labels:\n",
    "        print(label)\n",
    "        trajs = traj_lab_dict[label][0][0]\n",
    "        \n",
    "        # Loop over all the 100 simulations\n",
    "        timegapForEverySim = np.zeros(len(trajs))\n",
    "        \n",
    "        # Every element i.e. sim is a (200,100,66) array\n",
    "        for simNum, sim in enumerate(trajs):\n",
    "            timegapForEverySim[simNum] = \\\n",
    "            timegapAvgOverHorizonAvgOverCars(\n",
    "                sim['observations'][:,:,observation_indexes['timegap']])\n",
    "            \n",
    "        print(np.mean(timegapForEverySim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 100, 66)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajs[0]['observations'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
